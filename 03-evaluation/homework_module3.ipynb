{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a90797c-aee0-49c5-9275-525a118c1c1e",
   "metadata": {},
   "source": [
    "# Homework Module 3 LLM Zoomcamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429f4997-02d0-415a-b4b7-397f60a867a7",
   "metadata": {},
   "source": [
    "## Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f48f7ca-22a9-4355-a23e-b311fbb6f460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: minsearch in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.0.4)\n",
      "Requirement already satisfied: qdrant_client in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.15.0)\n",
      "Requirement already satisfied: fastembed in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.7.1)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.12/site-packages (from minsearch) (2.2.4)\n",
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.12/site-packages (from minsearch) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in /home/codespace/.local/lib/python3.12/site-packages (from minsearch) (1.6.1)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from qdrant_client) (1.73.0)\n",
      "Requirement already satisfied: httpx>=0.20.0 in /home/codespace/.local/lib/python3.12/site-packages (from httpx[http2]>=0.20.0->qdrant_client) (0.28.1)\n",
      "Requirement already satisfied: portalocker<4.0,>=2.7.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from qdrant_client) (2.10.1)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from qdrant_client) (6.31.1)\n",
      "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from qdrant_client) (2.11.5)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in /home/codespace/.local/lib/python3.12/site-packages (from qdrant_client) (2.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.20 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from fastembed) (0.34.1)\n",
      "Requirement already satisfied: loguru<0.8.0,>=0.7.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from fastembed) (0.7.3)\n",
      "Requirement already satisfied: mmh3<6.0.0,>=4.1.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from fastembed) (5.1.0)\n",
      "Requirement already satisfied: onnxruntime!=1.20.0,>=1.17.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from fastembed) (1.22.0)\n",
      "Requirement already satisfied: pillow<12.0.0,>=10.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from fastembed) (11.1.0)\n",
      "Requirement already satisfied: py-rust-stemmers<0.2.0,>=0.1.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from fastembed) (0.1.5)\n",
      "Requirement already satisfied: requests<3.0,>=2.31 in /home/codespace/.local/lib/python3.12/site-packages (from fastembed) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<1.0,>=0.15 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from fastembed) (0.21.1)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.66 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from fastembed) (4.67.1)\n",
      "Requirement already satisfied: anyio in /home/codespace/.local/lib/python3.12/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (4.9.0)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (1.0.7)\n",
      "Requirement already satisfied: idna in /home/codespace/.local/lib/python3.12/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (0.14.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from httpx[http2]>=0.20.0->qdrant_client) (4.2.0)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.20->fastembed) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.20->fastembed) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.20->fastembed) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.20->fastembed) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.20->fastembed) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.20->fastembed) (1.1.3)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/python/3.12.1/lib/python3.12/site-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/python/3.12.1/lib/python3.12/site-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed) (25.2.10)\n",
      "Requirement already satisfied: sympy in /home/codespace/.local/lib/python3.12/site-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed) (1.13.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0,>=2.31->fastembed) (3.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->minsearch) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->minsearch) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->minsearch) (2025.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn->minsearch) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn->minsearch) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn->minsearch) (3.6.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client) (4.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->minsearch) (1.17.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/codespace/.local/lib/python3.12/site-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from coloredlogs->onnxruntime!=1.20.0,>=1.17.0->fastembed) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy->onnxruntime!=1.20.0,>=1.17.0->fastembed) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U minsearch qdrant_client fastembed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f8a920-7ac1-4185-92bb-543788eb0b6f",
   "metadata": {},
   "source": [
    "## Evaluation data\n",
    "For this homework, we will use the same dataset we generated in the videos.\n",
    "\n",
    "Let's get them:\n",
    "\n",
    "```py\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url_prefix = 'https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/03-evaluation/'\n",
    "docs_url = url_prefix + 'search_evaluation/documents-with-ids.json'\n",
    "documents = requests.get(docs_url).json()\n",
    "\n",
    "ground_truth_url = url_prefix + 'search_evaluation/ground-truth-data.csv'\n",
    "df_ground_truth = pd.read_csv(ground_truth_url)\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')\n",
    "```\n",
    "\n",
    "Here, `documents` contains the documents from the FAQ database with unique IDs, and ground_truth contains generated question-answer pairs.\n",
    "\n",
    "Also, we will need the code for evaluating retrieval:\n",
    "\n",
    "```py\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)\n",
    "\n",
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['document']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a3fa2aa-e323-4fbd-8078-2df287b950a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url_prefix = 'https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/03-evaluation/'\n",
    "docs_url = url_prefix + 'search_evaluation/documents-with-ids.json'\n",
    "documents = requests.get(docs_url).json()\n",
    "\n",
    "ground_truth_url = url_prefix + 'search_evaluation/ground-truth-data.csv'\n",
    "df_ground_truth = pd.read_csv(ground_truth_url)\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "552172b0-4977-4aa2-8369-ac141d754360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)\n",
    "\n",
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['document']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0ac8ce-1f6d-4bc8-a449-c1dcaae9aab5",
   "metadata": {},
   "source": [
    "## Q1\n",
    "Now let's evaluate our usual minsearch approach, indexing documents with:\n",
    "```\n",
    "text_fields=[\"question\", \"section\", \"text\"],\n",
    "keyword_fields=[\"course\", \"id\"]\n",
    "```\n",
    "but tweak the parameters for search. Let's use the following boosting params:\n",
    "```\n",
    "boost = {'question': 1.5, 'section': 0.1}\n",
    "```\n",
    "What's the hitrate for this approach?\n",
    "- 0.64\n",
    "- 0.74\n",
    "- **0.84**\n",
    "- 0.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed518ca2-d2e0-4e5e-ace8-0928d9164ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>course</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When does the course begin?</td>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>c02e79ef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How can I get the course schedule?</td>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>c02e79ef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the link for course registration?</td>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>c02e79ef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How can I receive course announcements?</td>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>c02e79ef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Where do I join the Slack channel?</td>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>c02e79ef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4622</th>\n",
       "      <td>How should I destroy infrastructure created us...</td>\n",
       "      <td>mlops-zoomcamp</td>\n",
       "      <td>886d1617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4623</th>\n",
       "      <td>What is the first step to destroy AWS infrastr...</td>\n",
       "      <td>mlops-zoomcamp</td>\n",
       "      <td>886d1617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4624</th>\n",
       "      <td>Can I destroy infrastructure created with GitH...</td>\n",
       "      <td>mlops-zoomcamp</td>\n",
       "      <td>886d1617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4625</th>\n",
       "      <td>What command initializes Terraform with specif...</td>\n",
       "      <td>mlops-zoomcamp</td>\n",
       "      <td>886d1617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4626</th>\n",
       "      <td>How do you specify the variable file when runn...</td>\n",
       "      <td>mlops-zoomcamp</td>\n",
       "      <td>886d1617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4627 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "0                           When does the course begin?   \n",
       "1                    How can I get the course schedule?   \n",
       "2             What is the link for course registration?   \n",
       "3               How can I receive course announcements?   \n",
       "4                    Where do I join the Slack channel?   \n",
       "...                                                 ...   \n",
       "4622  How should I destroy infrastructure created us...   \n",
       "4623  What is the first step to destroy AWS infrastr...   \n",
       "4624  Can I destroy infrastructure created with GitH...   \n",
       "4625  What command initializes Terraform with specif...   \n",
       "4626  How do you specify the variable file when runn...   \n",
       "\n",
       "                         course  document  \n",
       "0     data-engineering-zoomcamp  c02e79ef  \n",
       "1     data-engineering-zoomcamp  c02e79ef  \n",
       "2     data-engineering-zoomcamp  c02e79ef  \n",
       "3     data-engineering-zoomcamp  c02e79ef  \n",
       "4     data-engineering-zoomcamp  c02e79ef  \n",
       "...                         ...       ...  \n",
       "4622             mlops-zoomcamp  886d1617  \n",
       "4623             mlops-zoomcamp  886d1617  \n",
       "4624             mlops-zoomcamp  886d1617  \n",
       "4625             mlops-zoomcamp  886d1617  \n",
       "4626             mlops-zoomcamp  886d1617  \n",
       "\n",
       "[4627 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc0b4148-2d21-4366-ba92-8b6ac92e56d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.minsearch.Index at 0x72b082fa5d90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import minsearch\n",
    "\n",
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"section\", \"text\"],\n",
    "    keyword_fields=[\"course\", \"id\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "931e9fa2-df98-4948-8f2e-19e3dd2d68f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_search(query, course):\n",
    "    boost = {'question': 1.5, 'section': 0.1}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': course},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a5f1fb0-e477-47cd-b8ac-46a58a456f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd2bfea1187441e86ce7d0891126211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "relevance_total = []\n",
    "\n",
    "for q in tqdm(ground_truth):\n",
    "    doc_id = q['document']\n",
    "    results = minsearch_search(query=q['question'], course=q['course'])\n",
    "    relevance = [d['id'] == doc_id for d in results]\n",
    "    relevance_total.append(relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a7f19bb-62b0-4f8f-a5fd-869a21ce3d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.848714069591528"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_rate(relevance_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f49df7a-828e-4a72-8685-4d46fa26f038",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "The latest version of minsearch also supports vector search. We will use it:\n",
    "```\n",
    "from minsearch import VectorSearch\n",
    "```\n",
    "We will also use TF-IDF and Singular Value Decomposition to create embeddings from texts. You can refer to our \"Create Your Own Search Engine\" workshop if you want to know more about it.\n",
    "```\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "```\n",
    "Let's create embeddings for the \"question\" field:\n",
    "```\n",
    "texts = []\n",
    "\n",
    "for doc in documents:\n",
    "    t = doc['question']\n",
    "    texts.append(t)\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3),\n",
    "    TruncatedSVD(n_components=128, random_state=1)\n",
    ")\n",
    "X = pipeline.fit_transform(texts)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "410ea495-cb0a-41cd-bff5-0cb5292c6323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minsearch import VectorSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "899f165c-d872-4240-9fcd-e297b2f7a74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68530402-aa6c-4eb4-a552-9815dc3f4200",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "\n",
    "for doc in documents:\n",
    "    t = doc['question']\n",
    "    texts.append(t)\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3),\n",
    "    TruncatedSVD(n_components=128, random_state=1)\n",
    ")\n",
    "X = pipeline.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ebeeea-3e34-4c20-8fab-c0b1e523797c",
   "metadata": {},
   "source": [
    "## Q2\n",
    "Now let's index these embeddings with minsearch:\n",
    "```\n",
    "vindex = VectorSearch(keyword_fields={'course'})\n",
    "vindex.fit(X, documents)\n",
    "```\n",
    "Evaluate this seach method. What's MRR for it?\n",
    "- 0.25\n",
    "- **0.35**\n",
    "- 0.45\n",
    "- 0.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "577edded-a94c-4e63-861c-28bd4b1c1dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.vector.VectorSearch at 0x72b081970b00>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vindex = VectorSearch(keyword_fields={'course'})\n",
    "vindex.fit(X, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0cdef8a-687b-4fcd-9268-b4cadff79034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the query vector from the ground truth\n",
    "query_texts = []\n",
    "\n",
    "for doc in ground_truth:\n",
    "    t = doc['question']\n",
    "    query_texts.append(t)\n",
    "\n",
    "questions = pipeline.transform(query_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fba87535-dbdd-4067-bcce-34f2988c3832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0cd97d873914f77ad6e0b17ee9a6c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.48173762697212014, 'mrr': 0.3572833369353793}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the evaluation and return the evaluation metrics\n",
    "relevance_total = []\n",
    "\n",
    "for i, q in enumerate(tqdm(ground_truth)):\n",
    "    doc_id = q['document']\n",
    "    results = vindex.search(query_vector=questions[i],\n",
    "                            filter_dict={'course': q['course']},\n",
    "                            num_results=5\n",
    "                           )\n",
    "    relevance = [d['id'] == doc_id for d in results]\n",
    "    relevance_total.append(relevance)\n",
    "\n",
    "eval_q2 = {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total)\n",
    "}\n",
    "eval_q2    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a728373-53cf-4ab4-8d38-dfa49a4f4b52",
   "metadata": {},
   "source": [
    "## Q3\n",
    "\n",
    "We only used question in Q2. We can use both question and answer:\n",
    "```\n",
    "texts = []\n",
    "\n",
    "for doc in documents:\n",
    "    t = doc['question'] + ' ' + doc['text']\n",
    "    texts.append(t)\n",
    "```\n",
    "Using the same pipeline (`min_df=3` for TF-IDF vectorizer and `n_components=128` for SVD), evaluate the performance of this approach\n",
    "\n",
    "What's the hitrate?\n",
    "\n",
    "- 0.62\n",
    "- 0.72\n",
    "- **0.82**\n",
    "- 0.92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "357a5abc-b419-4303-b0b4-361d53880e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "\n",
    "for doc in documents:\n",
    "    t = doc['question'] + ' ' + doc['text']\n",
    "    texts.append(t)\n",
    "\n",
    "pipeline3 = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3),\n",
    "    TruncatedSVD(n_components=128, random_state=1)\n",
    ")\n",
    "X3 = pipeline3.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "956bcb6b-dc02-4604-99f6-38363d8f4870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.vector.VectorSearch at 0x72b081953fb0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vindex3 = VectorSearch(keyword_fields={'course'})\n",
    "vindex3.fit(X3, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63868f45-cd13-4eee-ad44-3bbb50d99efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the query vector from the ground truth\n",
    "query_texts = []\n",
    "\n",
    "for doc in ground_truth:\n",
    "    t = doc['question']\n",
    "    query_texts.append(t)\n",
    "\n",
    "questions3 = pipeline3.transform(query_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8748d32e-274e-419f-b092-6456461c6f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "151624dd9c504e0fa5e9957821665f09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.8210503566025502, 'mrr': 0.6717347453353508}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the evaluation and return the evaluation metrics\n",
    "relevance_total3 = []\n",
    "\n",
    "for i, q in enumerate(tqdm(ground_truth)):\n",
    "    doc_id = q['document']\n",
    "    results = vindex3.search(query_vector=questions3[i],\n",
    "                            filter_dict={'course': q['course']},\n",
    "                            num_results=5\n",
    "                           )\n",
    "    relevance = [d['id'] == doc_id for d in results]\n",
    "    relevance_total3.append(relevance)\n",
    "\n",
    "eval_q3 = {\n",
    "        'hit_rate': hit_rate(relevance_total3),\n",
    "        'mrr': mrr(relevance_total3)\n",
    "}\n",
    "eval_q3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923e2d1e-5a76-498f-9791-cce055a6b916",
   "metadata": {},
   "source": [
    "## Q4\n",
    "\n",
    "Now let's evaluate the following settings in Qdrant:\n",
    "\n",
    "- `text = doc['question'] + ' ' + doc['text']`\n",
    "- `model_handle = \"jinaai/jina-embeddings-v2-small-en\"`\n",
    "- `limit = 5`\n",
    "\n",
    "What's the MRR?\n",
    "\n",
    "- 0.65\n",
    "- 0.75\n",
    "- **0.85**\n",
    "- 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7846d617-32ec-46b2-89b3-7def10a41153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "from fastembed import TextEmbedding\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5350de5-541f-4fb4-a753-45d018920b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the client\n",
    "client = QdrantClient(\"http://localhost:6333\") #connecting to local Qdrant instanceb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8b8db1d-8843-40c9-b0d8-23f161877015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a collection\n",
    "query = 'I just discovered the course. Can I join now?'\n",
    "model_handle = \"jinaai/jina-embeddings-v2-small-en\"\n",
    "collection_name = \"HW3\"\n",
    "EMBEDDING_DIMENSIONALITY = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81ca02a5-7d9c-40e4-aae0-c98336a2c841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'HW3' deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "# Delete the collection\n",
    "try:\n",
    "    client.delete_collection(collection_name=collection_name)\n",
    "    print(f\"Collection '{collection_name}' deleted successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error deleting collection '{collection_name}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d25bfce-49a2-4ee5-b922-b585054ddc5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the collection with specified vector parameters\n",
    "# Run only ONCE\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=EMBEDDING_DIMENSIONALITY,  # Dimensionality of the vectors\n",
    "        distance=models.Distance.COSINE  # Distance metric for similarity search\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f6a0922-3da8-465e-86b2-e021fa9af077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp',\n",
       " 'id': 'c02e79ef'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad50394b-e89f-4641-854b-c5cc0c423f7d",
   "metadata": {},
   "source": [
    "### Upsert the documents to Qdrant client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "447f9a55-7d4e-4dbb-9928-59344ef87f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "\n",
    "for i, doc in enumerate(documents):\n",
    "    point = models.PointStruct(\n",
    "        id = i,\n",
    "        vector = models.Document(text=doc['question'] + ' ' + doc['text'],\n",
    "                                 model=model_handle),\n",
    "        payload = {\n",
    "            \"doc_id\": doc['id']\n",
    "        }\n",
    "    )\n",
    "    points.append(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e552178-ce0e-4b0c-8671-8694d6c6ac40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=points\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b440d47-3e34-43bf-83c9-6968578a6b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qdrant_search(query, limit=5):\n",
    "\n",
    "    results = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.Document( #embed the query text locally with \"jinaai/jina-embeddings-v2-small-en\"\n",
    "            text=query,\n",
    "            model=model_handle \n",
    "        ),\n",
    "        limit=limit, # top closest matches\n",
    "        with_payload=True #to get metadata in the results\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1fb3a6fa-0e1e-4bbd-88b6-781a9bc3dc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('points',\n",
       "  [ScoredPoint(id=449, version=0, score=0.8620738, payload={'doc_id': 'ee58a693'}, vector=None, shard_key=None, order_value=None),\n",
       "   ScoredPoint(id=2, version=0, score=0.8514544, payload={'doc_id': '7842b56a'}, vector=None, shard_key=None, order_value=None),\n",
       "   ScoredPoint(id=7, version=0, score=0.8436594, payload={'doc_id': 'a482086d'}, vector=None, shard_key=None, order_value=None),\n",
       "   ScoredPoint(id=0, version=0, score=0.84082866, payload={'doc_id': 'c02e79ef'}, vector=None, shard_key=None, order_value=None),\n",
       "   ScoredPoint(id=452, version=0, score=0.83894074, payload={'doc_id': '0a278fb2'}, vector=None, shard_key=None, order_value=None)])]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [d for d in qdrant_search(query)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e1be8cda-ebb6-46d0-9bab-f4816f2de6e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ee58a693', '7842b56a', 'a482086d', 'c02e79ef', '0a278fb2']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [j.payload['doc_id'] for d in qdrant_search(query) for j in d[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "79fa7217-a23b-4314-bbbe-a0333daf5700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['document']\n",
    "        results = search_function(q)\n",
    "        relevance = [j.payload['doc_id'] == doc_id for d in results for j in d[1]]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00e6da0f-9156-4c7d-8474-6289909e951d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e004c24e0bd47d6b2f8a598b4488687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.9118219148476334, 'mrr': 0.8247172393919758}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: qdrant_search(q['question']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10021a6-012a-44d7-9b11-5be19ed7a8ac",
   "metadata": {},
   "source": [
    "## Q5\n",
    "\n",
    "In the second part of the module, we looked at evaluating the entire RAG approach. In particular, we looked at comparing the answer generated by our system with the actual answer from the FAQ.\n",
    "\n",
    "One of the ways of doing it is using the cosine similarity. Let's see how to calculate it.\n",
    "\n",
    "Cosine similarity is a dot product between two normalized vectors. In geometrical sense, it's the cosine of the angle between the vectors. Look up \"cosine similarity geometry\" if you want to learn more about it.\n",
    "\n",
    "For us, it means that we need two things:\n",
    "\n",
    "First, we normalize each of the vectors\n",
    "Then, compute the dot product\n",
    "So, we get this:\n",
    "```\n",
    "def cosine(u, v):\n",
    "    u = normalize(u)\n",
    "    v = normalize(v)\n",
    "    return u.dot(v)\n",
    "```\n",
    "For normalization, we first compute the vector norm (its length), and then divide the vector by it:\n",
    "```\n",
    "def normalize(u):\n",
    "    norm = np.sqrt(u.dot(u))\n",
    "    return u / norm\n",
    "```\n",
    "(where np is import numpy as np)\n",
    "\n",
    "Or we can simplify it:\n",
    "```\n",
    "def cosine(u, v):\n",
    "    u_norm = np.sqrt(u.dot(u))\n",
    "    v_norm = np.sqrt(v.dot(v))\n",
    "    return u.dot(v) / (u_norm * v_norm)\n",
    "```\n",
    "Now let's use this function to compute the A->Q->A cosine similarity.\n",
    "\n",
    "We will use the results from our gpt-4o-mini evaluations:\n",
    "```\n",
    "results_url = url_prefix + 'rag_evaluation/data/results-gpt4o-mini.csv'\n",
    "df_results = pd.read_csv(results_url)\n",
    "```\n",
    "When creating embeddings, we will use a simple way - the same we used in the Embeddings section:\n",
    "```\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3),\n",
    "    TruncatedSVD(n_components=128, random_state=1)\n",
    ")\n",
    "```\n",
    "Let's fit the vectorizer on all the text data we have:\n",
    "```\n",
    "pipeline.fit(df_results.answer_llm + ' ' + df_results.answer_orig + ' ' + df_results.question)\n",
    "```\n",
    "Now use the transform methon of the pipeline to create the embeddings and calculate the cosine similarity between each pair.\n",
    "\n",
    "What's the average cosine?\n",
    "\n",
    "- 0.64\n",
    "- 0.74\n",
    "- **0.84**\n",
    "- 0.94\n",
    "\n",
    "This is how you do it:\n",
    "\n",
    "- For each answer pair, compute\n",
    "    - v_llm for the answer from the LLM\n",
    "    - v_orig for the original answer\n",
    "    - then compute the cosine between them\n",
    "- At the end, take the average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "92027b20-e3fb-44e8-82d0-392070961466",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_url = url_prefix + 'rag_evaluation/data/results-gpt4o-mini.csv'\n",
    "df_results = pd.read_csv(results_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "34c91b1e-1fbc-4dbf-a048-e0bd7d4857a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>answer_orig</th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You can sign up for the course by visiting the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Where can I sign up for the course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You can sign up using the link provided in the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Can you provide a link to sign up?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes, there is an FAQ for the Machine Learning ...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Is there an FAQ for this Machine Learning course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The context does not provide any specific info...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Does this course have a GitHub repository for ...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To structure your questions and answers for th...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>How can I structure my questions and answers f...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>Some suggested titles for listing the Machine ...</td>\n",
       "      <td>I’ve seen LinkedIn users list DataTalksClub as...</td>\n",
       "      <td>c6a22665</td>\n",
       "      <td>What are some suggested titles for listing the...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>It is best advised that you do not list the Ma...</td>\n",
       "      <td>I’ve seen LinkedIn users list DataTalksClub as...</td>\n",
       "      <td>c6a22665</td>\n",
       "      <td>Should I list the Machine Learning Zoomcamp ex...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>You can incorporate your Machine Learning Zoom...</td>\n",
       "      <td>I’ve seen LinkedIn users list DataTalksClub as...</td>\n",
       "      <td>c6a22665</td>\n",
       "      <td>In which LinkedIn sections can I incorporate m...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>The advice on including a project link in a CV...</td>\n",
       "      <td>I’ve seen LinkedIn users list DataTalksClub as...</td>\n",
       "      <td>c6a22665</td>\n",
       "      <td>Who gave advice on including a project link in...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829</th>\n",
       "      <td>The suggestion to showcase progress through Li...</td>\n",
       "      <td>I’ve seen LinkedIn users list DataTalksClub as...</td>\n",
       "      <td>c6a22665</td>\n",
       "      <td>Who suggested showcasing progress through Link...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1830 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             answer_llm  \\\n",
       "0     You can sign up for the course by visiting the...   \n",
       "1     You can sign up using the link provided in the...   \n",
       "2     Yes, there is an FAQ for the Machine Learning ...   \n",
       "3     The context does not provide any specific info...   \n",
       "4     To structure your questions and answers for th...   \n",
       "...                                                 ...   \n",
       "1825  Some suggested titles for listing the Machine ...   \n",
       "1826  It is best advised that you do not list the Ma...   \n",
       "1827  You can incorporate your Machine Learning Zoom...   \n",
       "1828  The advice on including a project link in a CV...   \n",
       "1829  The suggestion to showcase progress through Li...   \n",
       "\n",
       "                                            answer_orig  document  \\\n",
       "0     Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "1     Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "2     Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "3     Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "4     Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "...                                                 ...       ...   \n",
       "1825  I’ve seen LinkedIn users list DataTalksClub as...  c6a22665   \n",
       "1826  I’ve seen LinkedIn users list DataTalksClub as...  c6a22665   \n",
       "1827  I’ve seen LinkedIn users list DataTalksClub as...  c6a22665   \n",
       "1828  I’ve seen LinkedIn users list DataTalksClub as...  c6a22665   \n",
       "1829  I’ve seen LinkedIn users list DataTalksClub as...  c6a22665   \n",
       "\n",
       "                                               question  \\\n",
       "0                   Where can I sign up for the course?   \n",
       "1                    Can you provide a link to sign up?   \n",
       "2     Is there an FAQ for this Machine Learning course?   \n",
       "3     Does this course have a GitHub repository for ...   \n",
       "4     How can I structure my questions and answers f...   \n",
       "...                                                 ...   \n",
       "1825  What are some suggested titles for listing the...   \n",
       "1826  Should I list the Machine Learning Zoomcamp ex...   \n",
       "1827  In which LinkedIn sections can I incorporate m...   \n",
       "1828  Who gave advice on including a project link in...   \n",
       "1829  Who suggested showcasing progress through Link...   \n",
       "\n",
       "                         course  \n",
       "0     machine-learning-zoomcamp  \n",
       "1     machine-learning-zoomcamp  \n",
       "2     machine-learning-zoomcamp  \n",
       "3     machine-learning-zoomcamp  \n",
       "4     machine-learning-zoomcamp  \n",
       "...                         ...  \n",
       "1825  machine-learning-zoomcamp  \n",
       "1826  machine-learning-zoomcamp  \n",
       "1827  machine-learning-zoomcamp  \n",
       "1828  machine-learning-zoomcamp  \n",
       "1829  machine-learning-zoomcamp  \n",
       "\n",
       "[1830 rows x 5 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5ac73704-d307-4854-8888-25143954502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3),\n",
    "    TruncatedSVD(n_components=128, random_state=1)\n",
    ")\n",
    "X = pipeline.fit_transform(df_results.answer_llm + ' ' + df_results.answer_orig + ' ' + df_results.question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "94d1c0ee-ca0b-4ace-9620-3b820199a29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.15549859,  0.11219644, -0.12744873, ...,  0.02800749,\n",
       "        -0.00089034,  0.01145811],\n",
       "       [ 0.14894279,  0.17679214, -0.16144508, ...,  0.02846803,\n",
       "        -0.00530882, -0.02534412],\n",
       "       [ 0.2624874 ,  0.14431318, -0.1935808 , ...,  0.03976003,\n",
       "        -0.00854878, -0.02342486],\n",
       "       ...,\n",
       "       [ 0.1333508 ,  0.08705736, -0.09715167, ...,  0.03925748,\n",
       "        -0.01131956, -0.01923416],\n",
       "       [ 0.10213099,  0.01932364, -0.020402  , ...,  0.03760978,\n",
       "        -0.00202926,  0.01866861],\n",
       "       [ 0.07329588, -0.00118814, -0.00599569, ...,  0.03757046,\n",
       "        -0.01849048,  0.03805752]], shape=(1830, 128))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_llm = pipeline.transform(df_results.answer_llm)\n",
    "X_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "10d164e7-507d-4bd3-8d37-a5ea0772c6b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.22746773,  0.12079642, -0.17785901, ...,  0.08439231,\n",
       "        -0.03839994, -0.05823001],\n",
       "       [ 0.22746773,  0.12079642, -0.17785901, ...,  0.08439231,\n",
       "        -0.03839994, -0.05823001],\n",
       "       [ 0.22746773,  0.12079642, -0.17785901, ...,  0.08439231,\n",
       "        -0.03839994, -0.05823001],\n",
       "       ...,\n",
       "       [ 0.18375337,  0.05955752, -0.09660538, ...,  0.05882618,\n",
       "        -0.01491182, -0.00757821],\n",
       "       [ 0.18375337,  0.05955752, -0.09660538, ...,  0.05882618,\n",
       "        -0.01491182, -0.00757821],\n",
       "       [ 0.18375337,  0.05955752, -0.09660538, ...,  0.05882618,\n",
       "        -0.01491182, -0.00757821]], shape=(1830, 128))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_orig = pipeline.transform(df_results.answer_orig)\n",
    "X_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "777dfc9c-67a5-4190-b359-3f8df957b7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(u, v):\n",
    "    u_norm = np.sqrt(u.dot(u))\n",
    "    v_norm = np.sqrt(v.dot(v))\n",
    "    return u.dot(v) / (u_norm * v_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "88df7d7c-37e8-43d6-a0b9-c2a8c8c2931a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.4635262016002998),\n",
       " np.float64(0.7815651064829406),\n",
       " np.float64(0.8891577173455293),\n",
       " np.float64(0.6149615816691357),\n",
       " np.float64(0.6240861551352463)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cosine = [cosine(u,v) for u,v in zip(X_llm, X_orig)]\n",
    "all_cosine[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cd2535fd-8afc-411d-9357-e4278ec34fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8415841233490402)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca26792-fa5e-4726-87fc-45aa1f832508",
   "metadata": {},
   "source": [
    "## Q6\n",
    "\n",
    "And alternative way to see how two texts are similar is ROUGE.\n",
    "\n",
    "This is a set of metrics that compares two answers based on the overlap of n-grams, word sequences, and word pairs.\n",
    "\n",
    "It can give a more nuanced view of text similarity than just cosine similarity alone.\n",
    "\n",
    "We don't need to implement it ourselves, there's a python package for it:\n",
    "```\n",
    "pip install rouge\n",
    "```\n",
    "(The latest version at the moment of writing is 1.0.1)\n",
    "\n",
    "Let's compute the ROUGE score between the answers at the index 10 of our dataframe (doc_id=5170565b)\n",
    "```\n",
    "from rouge import Rouge\n",
    "rouge_scorer = Rouge()\n",
    "\n",
    "r = df_results.iloc[10]\n",
    "scores = rouge_scorer.get_scores(r.answer_llm, r.answer_orig)[0]\n",
    "scores\n",
    "```\n",
    "There are three scores: rouge-1, rouge-2 and rouge-l, and precision, recall and F1 score for each.\n",
    "\n",
    "rouge-1 - the overlap of unigrams,\n",
    "rouge-2 - bigrams,\n",
    "rouge-l - the longest common subsequence\n",
    "For the 10th document, Rouge-1 F1 score is 0.45\n",
    "\n",
    "Let's compute it for the pairs in the entire dataframe. What's the average Rouge-1 F1?\n",
    "\n",
    "- 0.25\n",
    "- **0.35**\n",
    "- 0.45\n",
    "- 0.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "73f28c2d-f8bc-4c06-98d9-5a9a7374e89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: six in /home/codespace/.local/lib/python3.12/site-packages (from rouge) (1.17.0)\n",
      "Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a16e1c7f-83df-4cd2-a32b-b187198b8362",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "rouge_scorer = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5abbc572-dd84-4f6a-a076-e1545c28c13d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.45454545454545453,\n",
       "  'p': 0.45454545454545453,\n",
       "  'f': 0.45454544954545456},\n",
       " 'rouge-2': {'r': 0.21621621621621623,\n",
       "  'p': 0.21621621621621623,\n",
       "  'f': 0.21621621121621637},\n",
       " 'rouge-l': {'r': 0.3939393939393939,\n",
       "  'p': 0.3939393939393939,\n",
       "  'f': 0.393939388939394}}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = df_results.iloc[10]\n",
    "scores = rouge_scorer.get_scores(r.answer_llm, r.answer_orig)[0]\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3ddb1385-4802-4ae4-b224-e3ab8f5541f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>answer_orig</th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You can sign up for the course by visiting the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Where can I sign up for the course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You can sign up using the link provided in the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Can you provide a link to sign up?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes, there is an FAQ for the Machine Learning ...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Is there an FAQ for this Machine Learning course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The context does not provide any specific info...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Does this course have a GitHub repository for ...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To structure your questions and answers for th...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>How can I structure my questions and answers f...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>Some suggested titles for listing the Machine ...</td>\n",
       "      <td>I’ve seen LinkedIn users list DataTalksClub as...</td>\n",
       "      <td>c6a22665</td>\n",
       "      <td>What are some suggested titles for listing the...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>It is best advised that you do not list the Ma...</td>\n",
       "      <td>I’ve seen LinkedIn users list DataTalksClub as...</td>\n",
       "      <td>c6a22665</td>\n",
       "      <td>Should I list the Machine Learning Zoomcamp ex...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>You can incorporate your Machine Learning Zoom...</td>\n",
       "      <td>I’ve seen LinkedIn users list DataTalksClub as...</td>\n",
       "      <td>c6a22665</td>\n",
       "      <td>In which LinkedIn sections can I incorporate m...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>The advice on including a project link in a CV...</td>\n",
       "      <td>I’ve seen LinkedIn users list DataTalksClub as...</td>\n",
       "      <td>c6a22665</td>\n",
       "      <td>Who gave advice on including a project link in...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829</th>\n",
       "      <td>The suggestion to showcase progress through Li...</td>\n",
       "      <td>I’ve seen LinkedIn users list DataTalksClub as...</td>\n",
       "      <td>c6a22665</td>\n",
       "      <td>Who suggested showcasing progress through Link...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1830 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             answer_llm  \\\n",
       "0     You can sign up for the course by visiting the...   \n",
       "1     You can sign up using the link provided in the...   \n",
       "2     Yes, there is an FAQ for the Machine Learning ...   \n",
       "3     The context does not provide any specific info...   \n",
       "4     To structure your questions and answers for th...   \n",
       "...                                                 ...   \n",
       "1825  Some suggested titles for listing the Machine ...   \n",
       "1826  It is best advised that you do not list the Ma...   \n",
       "1827  You can incorporate your Machine Learning Zoom...   \n",
       "1828  The advice on including a project link in a CV...   \n",
       "1829  The suggestion to showcase progress through Li...   \n",
       "\n",
       "                                            answer_orig  document  \\\n",
       "0     Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "1     Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "2     Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "3     Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "4     Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "...                                                 ...       ...   \n",
       "1825  I’ve seen LinkedIn users list DataTalksClub as...  c6a22665   \n",
       "1826  I’ve seen LinkedIn users list DataTalksClub as...  c6a22665   \n",
       "1827  I’ve seen LinkedIn users list DataTalksClub as...  c6a22665   \n",
       "1828  I’ve seen LinkedIn users list DataTalksClub as...  c6a22665   \n",
       "1829  I’ve seen LinkedIn users list DataTalksClub as...  c6a22665   \n",
       "\n",
       "                                               question  \\\n",
       "0                   Where can I sign up for the course?   \n",
       "1                    Can you provide a link to sign up?   \n",
       "2     Is there an FAQ for this Machine Learning course?   \n",
       "3     Does this course have a GitHub repository for ...   \n",
       "4     How can I structure my questions and answers f...   \n",
       "...                                                 ...   \n",
       "1825  What are some suggested titles for listing the...   \n",
       "1826  Should I list the Machine Learning Zoomcamp ex...   \n",
       "1827  In which LinkedIn sections can I incorporate m...   \n",
       "1828  Who gave advice on including a project link in...   \n",
       "1829  Who suggested showcasing progress through Link...   \n",
       "\n",
       "                         course  \n",
       "0     machine-learning-zoomcamp  \n",
       "1     machine-learning-zoomcamp  \n",
       "2     machine-learning-zoomcamp  \n",
       "3     machine-learning-zoomcamp  \n",
       "4     machine-learning-zoomcamp  \n",
       "...                         ...  \n",
       "1825  machine-learning-zoomcamp  \n",
       "1826  machine-learning-zoomcamp  \n",
       "1827  machine-learning-zoomcamp  \n",
       "1828  machine-learning-zoomcamp  \n",
       "1829  machine-learning-zoomcamp  \n",
       "\n",
       "[1830 rows x 5 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8cba5b0d-ee85-40b1-ae2e-c916830a568b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.095238\n",
       "1       0.125000\n",
       "2       0.415584\n",
       "3       0.216216\n",
       "4       0.142076\n",
       "          ...   \n",
       "1825    0.336134\n",
       "1826    0.453782\n",
       "1827    0.442748\n",
       "1828    0.191489\n",
       "1829    0.147368\n",
       "Name: rouge-1, Length: 1830, dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fscore_rouge1 = pd.DataFrame.from_dict(rouge_scorer.get_scores(df_results.answer_llm, df_results.answer_orig))['rouge-1'].apply(lambda x: x['f'])\n",
    "fscore_rouge1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fda611cd-4531-4699-860e-a1b054df25ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1830.000000\n",
       "mean        0.351695\n",
       "std         0.158905\n",
       "min         0.000000\n",
       "25%         0.238887\n",
       "50%         0.356300\n",
       "75%         0.460133\n",
       "max         0.950000\n",
       "Name: rouge-1, dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fscore_rouge1.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
